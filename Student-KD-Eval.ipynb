{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3843cede-1a3d-48b2-a2ff-35fee0e6694b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset   \n",
    "from torch.utils.data import Dataset   \n",
    "from torch.utils.data import DataLoader   \n",
    "import torch   \n",
    "from transformers import AutoModelForSequenceClassification   \n",
    "from torch import nn, optim   \n",
    "from torch.nn import functional as F   \n",
    "from transformers import AutoTokenizer   \n",
    "from tqdm import tqdm   \n",
    "from time import perf_counter\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Apple GPU via Metal\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4bdcec0-33d9-4240-89ea-7bcfb3e6306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \"\"\"Custom dataset class for text classification with tokenization.\"\"\"\n",
    "    \n",
    "    def __init__(self, data: Any, tokenizer: Any, max_length: int = 150):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \n",
    "        Args:\n",
    "            data: Dataset containing 'label' and 'text' fields\n",
    "            tokenizer: Tokenizer for text processing\n",
    "            max_length: Maximum sequence length for tokenization\n",
    "        \"\"\"\n",
    "        self.targets = torch.tensor(data['label'])\n",
    "        texts = data['text']\n",
    "        \n",
    "        tokens = tokenizer(\n",
    "            texts, \n",
    "            return_tensors='pt', \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            max_length=max_length\n",
    "        )\n",
    "        \n",
    "        self.input_ids = tokens['input_ids']\n",
    "        self.attention_mask = tokens['attention_mask']\n",
    "        self.length = len(texts)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        return self.input_ids[index], self.attention_mask[index], self.targets[index]\n",
    "\n",
    "\n",
    "class DataManager:\n",
    "    \"\"\"Manages data loading and preprocessing for knowledge distillation.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_name: str, tokenizer: Any, test_size: float = 0.2, \n",
    "                 max_length: int = 150, batch_size: int = 32):\n",
    "        \"\"\"\n",
    "        Initialize data manager.\n",
    "        \n",
    "        Args:\n",
    "            dataset_name: Name of the dataset to load\n",
    "            tokenizer: Tokenizer for text processing\n",
    "            test_size: Fraction of data to use for validation\n",
    "            max_length: Maximum sequence length\n",
    "            batch_size: Batch size for data loaders\n",
    "        \"\"\"\n",
    "        self.dataset_name = dataset_name\n",
    "        self.tokenizer = tokenizer\n",
    "        self.test_size = test_size\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_loader = None\n",
    "        self.valid_loader = None\n",
    "        self.test_loader = None\n",
    "    \n",
    "    def prepare_data(self) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "        \"\"\"\n",
    "        Load and prepare data loaders.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (train_loader, valid_loader, test_loader)\n",
    "        \"\"\"\n",
    "        # Load dataset\n",
    "        data = load_dataset(self.dataset_name)\n",
    "        \n",
    "        # Split data\n",
    "        train_test = data['train'].train_test_split(test_size=self.test_size, shuffle=True)\n",
    "        train_data = train_test['train']\n",
    "        valid_data = train_test['test']\n",
    "        test_data = data['test']\n",
    "        \n",
    "        # Create custom datasets\n",
    "        train_dataset = TextDataset(train_data, self.tokenizer, self.max_length)\n",
    "        valid_dataset = TextDataset(valid_data, self.tokenizer, self.max_length)\n",
    "        test_dataset = TextDataset(test_data, self.tokenizer, self.max_length)\n",
    "        \n",
    "        # Create data loaders\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=self.batch_size)\n",
    "        self.valid_loader = DataLoader(valid_dataset, batch_size=self.batch_size)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=self.batch_size)\n",
    "        \n",
    "        return self.train_loader, self.valid_loader, self.test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e388cb06-0c25-4950-8e15-0d68237de4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "save_path = \"/Users/arsalsyed/Documents/student_model_distilled\"\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(save_path).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "\n",
    "data_manager = DataManager(\n",
    "    dataset_name=\"ag_news\",\n",
    "    tokenizer=tokenizer,\n",
    "    test_size=0.2,\n",
    "    max_length=150,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "train_loader, valid_loader, test_loader = data_manager.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5824fccc-305c-4ea2-91d1-57c1571e76bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(batch, model):\n",
    "    \"\"\"Helper function to get predictions from model\"\"\"\n",
    "    # Your batch has 3 tensors: input_ids, attention_mask, labels\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    \n",
    "    # Get the device of the model\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Move tensors to the same device as the model\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Pass both input_ids and attention_mask to the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        # Handle different model output formats\n",
    "        if hasattr(outputs, 'logits'):\n",
    "            logits = outputs.logits\n",
    "        else:\n",
    "            logits = outputs\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    return predictions.cpu().numpy(), labels.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5458aec8-148e-430e-922f-99c2319c19d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating student model on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 119/119 [00:41<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Overall Accuracy\n",
      "============================================================\n",
      "0.9469736842105263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "student_predictions = []\n",
    "student_labels = []\n",
    "accuracy_student = 0.0\n",
    "time_taken_student = 0.0\n",
    "\n",
    "# Evaluation loop\n",
    "print(\"Evaluating student model on test dataset...\")\n",
    "for batch in tqdm(test_loader):\n",
    "    # Student model evaluation\n",
    "    start_time = perf_counter()\n",
    "    student_preds, true_labels = get_predictions(batch, student_model)\n",
    "    end_time = perf_counter()\n",
    "    \n",
    "    student_predictions.extend(student_preds)\n",
    "    student_labels.extend(true_labels)\n",
    "    \n",
    "    # Calculate batch accuracy for student\n",
    "    batch_acc = accuracy_score(true_labels, student_preds)\n",
    "    accuracy_student += batch_acc\n",
    "    time_taken_student += end_time - start_time\n",
    "\n",
    "# Convert to numpy arrays\n",
    "student_predictions = np.array(student_predictions)\n",
    "student_labels = np.array(student_labels)\n",
    "\n",
    "# AG News dataset has 4 classes\n",
    "class_names = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "\n",
    "# Calculate comprehensive metrics for student model\n",
    "accuracy = accuracy_score(student_labels, student_predictions)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(student_labels, student_predictions, average='weighted')\n",
    "macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(student_labels, student_predictions, average='macro')\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Overall Accuracy\")\n",
    "print(f\"{'='*60}\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95090a10-7a1d-4093-9859-b3d8a2c6753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DETAILED CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World     0.9644    0.9547    0.9595      1900\n",
      "      Sports     0.9874    0.9884    0.9879      1900\n",
      "    Business     0.9216    0.9153    0.9184      1900\n",
      "    Sci/Tech     0.9150    0.9295    0.9222      1900\n",
      "\n",
      "    accuracy                         0.9470      7600\n",
      "   macro avg     0.9471    0.9470    0.9470      7600\n",
      "weighted avg     0.9471    0.9470    0.9470      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DETAILED CLASSIFICATION REPORT\")\n",
    "print(f\"{'='*60}\")\n",
    "print(classification_report(student_labels, student_predictions, \n",
    "                          target_names=class_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
